{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Tweet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries/packages\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweeets.json file and parse into a Python dictionary\n",
    "tweet_list = []\n",
    "with open('tax_tweets.json') as f:\n",
    "    for line in f:\n",
    "        tweet_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'contributors': None,\n",
      "  'coordinates': None,\n",
      "  'created_at': 'Tue Apr 19 03:58:52 +0000 2016',\n",
      "  'entities': {'hashtags': [],\n",
      "               'symbols': [],\n",
      "               'urls': [],\n",
      "               'user_mentions': [{'id': 110606529,\n",
      "                                  'id_str': '110606529',\n",
      "                                  'indices': [3, 15],\n",
      "                                  'name': 'Jack Graham',\n",
      "                                  'screen_name': 'jackngraham'}]},\n",
      "  'favorite_count': 0,\n",
      "  'favorited': False,\n",
      "  'filter_level': 'low',\n",
      "  'geo': None,\n",
      "  'id': 722273234150789120,\n",
      "  'id_str': '722273234150789120',\n",
      "  'in_reply_to_screen_name': None,\n",
      "  'in_reply_to_status_id': None,\n",
      "  'in_reply_to_status_id_str': None,\n",
      "  'in_reply_to_user_id': None,\n",
      "  'in_reply_to_user_id_str': None,\n",
      "  'is_quote_status': False,\n",
      "  'lang': 'en',\n",
      "  'place': None,\n",
      "  'retweet_count': 0,\n",
      "  'retweeted': False,\n",
      "  'retweeted_status': {'contributors': None,\n",
      "                       'coordinates': None,\n",
      "                       'created_at': 'Mon Apr 18 12:24:01 +0000 2016',\n",
      "                       'entities': {'hashtags': [],\n",
      "                                    'symbols': [],\n",
      "                                    'urls': [],\n",
      "                                    'user_mentions': []},\n",
      "                       'favorite_count': 49,\n",
      "                       'favorited': False,\n",
      "                       'filter_level': 'low',\n",
      "                       'geo': None,\n",
      "                       'id': 722037969431830529,\n",
      "                       'id_str': '722037969431830529',\n",
      "                       'in_reply_to_screen_name': None,\n",
      "                       'in_reply_to_status_id': None,\n",
      "                       'in_reply_to_status_id_str': None,\n",
      "                       'in_reply_to_user_id': None,\n",
      "                       'in_reply_to_user_id_str': None,\n",
      "                       'is_quote_status': False,\n",
      "                       'lang': 'en',\n",
      "                       'place': None,\n",
      "                       'retweet_count': 18,\n",
      "                       'retweeted': False,\n",
      "                       'source': '<a href=\"http://www.echofon.com/\" '\n",
      "                                 'rel=\"nofollow\">Echofon</a>',\n",
      "                       'text': 'There are 7 days in a week and Someday is not '\n",
      "                               'one of them. This is the day the Lord has '\n",
      "                               'made. Celebrate it even tho it is Taxday!!!',\n",
      "                       'truncated': False,\n",
      "                       'user': {'contributors_enabled': False,\n",
      "                                'created_at': 'Tue Feb 02 04:04:41 +0000 2010',\n",
      "                                'default_profile': True,\n",
      "                                'default_profile_image': False,\n",
      "                                'description': 'Pastor Prestonwood. Speaker '\n",
      "                                               'PowerPoint. Following Jesus. '\n",
      "                                               'Loving my family',\n",
      "                                'favourites_count': 0,\n",
      "                                'follow_request_sent': None,\n",
      "                                'followers_count': 33653,\n",
      "                                'following': None,\n",
      "                                'friends_count': 316,\n",
      "                                'geo_enabled': True,\n",
      "                                'id': 110606529,\n",
      "                                'id_str': '110606529',\n",
      "                                'is_translator': False,\n",
      "                                'lang': 'en',\n",
      "                                'listed_count': 434,\n",
      "                                'location': None,\n",
      "                                'name': 'Jack Graham',\n",
      "                                'notifications': None,\n",
      "                                'profile_background_color': 'C0DEED',\n",
      "                                'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "                                'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "                                'profile_background_tile': False,\n",
      "                                'profile_image_url': 'http://pbs.twimg.com/profile_images/469526860464783360/1Ip_Z2B-_normal.jpeg',\n",
      "                                'profile_image_url_https': 'https://pbs.twimg.com/profile_images/469526860464783360/1Ip_Z2B-_normal.jpeg',\n",
      "                                'profile_link_color': '0084B4',\n",
      "                                'profile_sidebar_border_color': 'C0DEED',\n",
      "                                'profile_sidebar_fill_color': 'DDEEF6',\n",
      "                                'profile_text_color': '333333',\n",
      "                                'profile_use_background_image': True,\n",
      "                                'protected': False,\n",
      "                                'screen_name': 'jackngraham',\n",
      "                                'statuses_count': 8769,\n",
      "                                'time_zone': None,\n",
      "                                'url': 'http://jackgraham.org',\n",
      "                                'utc_offset': None,\n",
      "                                'verified': False}},\n",
      "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web '\n",
      "            'Client</a>',\n",
      "  'text': 'RT @jackngraham: There are 7 days in a week and Someday is not one '\n",
      "          'of them. This is the day the Lord has made. Celebrate it even tho '\n",
      "          'it is…',\n",
      "  'timestamp_ms': '1461038332866',\n",
      "  'truncated': False,\n",
      "  'user': {'contributors_enabled': False,\n",
      "           'created_at': 'Wed Mar 18 05:34:15 +0000 2009',\n",
      "           'default_profile': False,\n",
      "           'default_profile_image': False,\n",
      "           'description': None,\n",
      "           'favourites_count': 928,\n",
      "           'follow_request_sent': None,\n",
      "           'followers_count': 85,\n",
      "           'following': None,\n",
      "           'friends_count': 210,\n",
      "           'geo_enabled': False,\n",
      "           'id': 25034105,\n",
      "           'id_str': '25034105',\n",
      "           'is_translator': False,\n",
      "           'lang': 'en',\n",
      "           'listed_count': 4,\n",
      "           'location': 'Dallas, Texas',\n",
      "           'name': 'LaTrelle Smart',\n",
      "           'notifications': None,\n",
      "           'profile_background_color': '0099B9',\n",
      "           'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme4/bg.gif',\n",
      "           'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme4/bg.gif',\n",
      "           'profile_background_tile': False,\n",
      "           'profile_image_url': 'http://pbs.twimg.com/profile_images/1455451250/LaTrelle_2011_normal.jpg',\n",
      "           'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1455451250/LaTrelle_2011_normal.jpg',\n",
      "           'profile_link_color': '0099B9',\n",
      "           'profile_sidebar_border_color': '5ED4DC',\n",
      "           'profile_sidebar_fill_color': '95E8EC',\n",
      "           'profile_text_color': '3C3940',\n",
      "           'profile_use_background_image': True,\n",
      "           'protected': False,\n",
      "           'screen_name': 'LaTrelleSmart',\n",
      "           'statuses_count': 916,\n",
      "           'time_zone': 'Central Time (US & Canada)',\n",
      "           'url': 'http://smartoutsourcesolutions.com',\n",
      "           'utc_offset': -18000,\n",
      "           'verified': False}}]\n"
     ]
    }
   ],
   "source": [
    "# Check structure of Tweet JSON file\n",
    "pprint.pprint(tweet_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tweet class to store attributes for each tweet\n",
    "\n",
    "class TaxTweets(object):\n",
    "    \n",
    "    def __init__(self, screen_name=\"\", profile_description=\"\", \n",
    "                 text=\"\", user_mentions=\"\"):\n",
    "        self.screen_name = screen_name\n",
    "        self.profile_description = profile_description\n",
    "        self.text = text\n",
    "        self.user_mentions = user_mentions\n",
    "        \n",
    "    def get_screen_name(self):\n",
    "        \"\"\"return screen name of twitter user\"\"\"\n",
    "        return self.screen_name\n",
    "    \n",
    "    def get_profile_description(self):\n",
    "        \"\"\"return profile description of user\"\"\"\n",
    "        return self.profile_description\n",
    "    \n",
    "    def get_text(self):\n",
    "        \"\"\"return text of twitter user\"\"\"\n",
    "        return self.text\n",
    "    \n",
    "    def get_user_mentions(self):\n",
    "        \"\"\"return screen names of users mentioned in tweet\"\"\"\n",
    "        return self.user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store each tweet set of attributes\n",
    "tweet_list2 = []\n",
    "\n",
    "# Iterate over each tweet set and get username, text, users mentioned, and \n",
    "# profile description in the tweet\n",
    "for tweet in tweet_list:\n",
    "    \n",
    "    user_mentions_list = [tweet['entities']['user_mentions'][i]['screen_name']\n",
    "                          for i in range(0, len(tweet['entities']['user_mentions']))]\n",
    "        \n",
    "    tweet_list2.append(TaxTweets(tweet['user']['screen_name'], \n",
    "                                 tweet['user']['description'],\n",
    "                                 tweet['text'],\n",
    "                                 user_mentions_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweets DataFrame\n",
    "\n",
    "# Set column names\n",
    "column_names = ('ScreenName', 'Profile_Description', 'Text', 'User_Mentions')\n",
    "# Create an empty dictionary to hold tweet sets\n",
    "dict_list = []\n",
    "\n",
    "# Iterate over each tweet set in list and zip together tweet attributes along\n",
    "# with column name to create dataframe\n",
    "for tweet in tweet_list2:\n",
    "    dict_list.append(dict(zip(column_names,\n",
    "                                  [tweet.get_screen_name(), \n",
    "                                   tweet.get_profile_description(),\n",
    "                                   tweet.get_text(), \n",
    "                                   tweet.get_user_mentions()\n",
    "                                  ]\n",
    "                             )))\n",
    "\n",
    "# Create tweets dataframe\n",
    "tweet_df = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>Award winning Designer/ Architect/ Design Dire...</td>\n",
       "      <td>RKMustafa</td>\n",
       "      <td>Stop Trying To File Your Tax Returns From Coac...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>Jus a Single laid bac kat who likes 2hav a goo...</td>\n",
       "      <td>DurdyGP</td>\n",
       "      <td>RT @CBSLA: Some Coachella goers tried to mail ...</td>\n",
       "      <td>[CBSLA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>we will see</td>\n",
       "      <td>queensusana24</td>\n",
       "      <td>Press TV Interview: G-20 Crackdown on Tax Have...</td>\n",
       "      <td>[1lefthook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>None</td>\n",
       "      <td>chiquisholla</td>\n",
       "      <td>RT @InmigrantNacion: @JimPressOffice\\n#AINF\\n#...</td>\n",
       "      <td>[InmigrantNacion, JimPressOffice, GOP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>@SpaceX once responded to a mission idea I had...</td>\n",
       "      <td>HAL9000and1</td>\n",
       "      <td>Hi, we're NASA and we want tax payers money......</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>North Broward Preparatory School June 26, 1993</td>\n",
       "      <td>tam1i</td>\n",
       "      <td>6 Good Reasons to File a Tax Extension #TaxDea...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>DissidentRight publishes original work through...</td>\n",
       "      <td>adissidentright</td>\n",
       "      <td>I *almost* pity the people who think of indivi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>None</td>\n",
       "      <td>nanner_lp</td>\n",
       "      <td>RT @micnews: This Michigan lawmaker explains w...</td>\n",
       "      <td>[micnews]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>None</td>\n",
       "      <td>Marchant9876</td>\n",
       "      <td>RT @margokingston1: Albo: Leaks show Govt adop...</td>\n",
       "      <td>[margokingston1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>‏صِلَتَُ بـ ربگ ، هيَّ بوابتك للحاة ،،\\nوَ على...</td>\n",
       "      <td>victoriasuthe17</td>\n",
       "      <td>RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...</td>\n",
       "      <td>[Adel__Almalki]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Profile_Description       ScreenName  \\\n",
       "4970  Award winning Designer/ Architect/ Design Dire...        RKMustafa   \n",
       "4971  Jus a Single laid bac kat who likes 2hav a goo...          DurdyGP   \n",
       "4972                                        we will see    queensusana24   \n",
       "4973                                               None     chiquisholla   \n",
       "4974  @SpaceX once responded to a mission idea I had...      HAL9000and1   \n",
       "4975     North Broward Preparatory School June 26, 1993            tam1i   \n",
       "4976  DissidentRight publishes original work through...  adissidentright   \n",
       "4977                                               None        nanner_lp   \n",
       "4978                                               None     Marchant9876   \n",
       "4979  ‏صِلَتَُ بـ ربگ ، هيَّ بوابتك للحاة ،،\\nوَ على...  victoriasuthe17   \n",
       "\n",
       "                                                   Text  \\\n",
       "4970  Stop Trying To File Your Tax Returns From Coac...   \n",
       "4971  RT @CBSLA: Some Coachella goers tried to mail ...   \n",
       "4972  Press TV Interview: G-20 Crackdown on Tax Have...   \n",
       "4973  RT @InmigrantNacion: @JimPressOffice\\n#AINF\\n#...   \n",
       "4974  Hi, we're NASA and we want tax payers money......   \n",
       "4975  6 Good Reasons to File a Tax Extension #TaxDea...   \n",
       "4976  I *almost* pity the people who think of indivi...   \n",
       "4977  RT @micnews: This Michigan lawmaker explains w...   \n",
       "4978  RT @margokingston1: Albo: Leaks show Govt adop...   \n",
       "4979  RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...   \n",
       "\n",
       "                               User_Mentions  \n",
       "4970                                      []  \n",
       "4971                                 [CBSLA]  \n",
       "4972                             [1lefthook]  \n",
       "4973  [InmigrantNacion, JimPressOffice, GOP]  \n",
       "4974                                      []  \n",
       "4975                                      []  \n",
       "4976                                      []  \n",
       "4977                               [micnews]  \n",
       "4978                        [margokingston1]  \n",
       "4979                         [Adel__Almalki]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 10 rows of tweets dataframe\n",
    "tweet_df.head(10)\n",
    "tweet_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries to clean up tweets\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stopwords to remove from tweets\n",
    "# List of stopwords taken from http://stackoverflow.com/questions/5511708/adding-words-to-nltk-stoplist\n",
    "stopword_list = []\n",
    "with open('stopwords.txt') as f:\n",
    "\n",
    "    for line in f:\n",
    "        line = line.split('\\n')\n",
    "        stopword_list.append(line[0])\n",
    "        \n",
    "# Add some Twitter specific words to the list\n",
    "stopword_list.append('rt')\n",
    "stopword_list.append('tax')\n",
    "stopword_list.append('taxday')\n",
    "stopword_list.append('taxes')\n",
    "\n",
    "# Create a string of punctuations and numbers to remove from the tweets\n",
    "punct_num = string.punctuation + string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(wordlist):\n",
    "    \"\"\"\n",
    "    Cleans up string by removing urls, numbers, and punctuations.\n",
    "    Strips white space.  \n",
    "    Makes the words lower case and splits up words.\n",
    "    Removes stop words.\n",
    "    \"\"\"\n",
    "    # Remove urls\n",
    "    # Reference: http://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet\n",
    "    wordlist = re.sub(r\"http\\S+\", \"\", wordlist)\n",
    "    \n",
    "    # Remove punctionations and numbers\n",
    "    for aChar in wordlist:\n",
    "        if aChar in punct_num:\n",
    "            wordlist = wordlist.replace(aChar, '')\n",
    "\n",
    "    # Strip white space, make lower case, and split into words\n",
    "    wordlist = wordlist.strip().lower().split()\n",
    "    \n",
    "    # Filter out stop words\n",
    "    wordlist2 = []\n",
    "    for aWord in wordlist:\n",
    "        if aWord not in stopword_list:\n",
    "            wordlist2.append(aWord)\n",
    "            \n",
    "    \n",
    "            \n",
    "    return wordlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the textProcessing function to tweet_df\n",
    "tweet_df['Text_Words'] = tweet_df['Text'].map(lambda x: textProcessing(x)).map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the User_Mentions column from a list to string\n",
    "tweet_df['User_Mentions'] = tweet_df['User_Mentions'].map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     jackngraham, days, week, someday, day, lord, c...\n",
       "1     turbotax, sound, taxesdone, music, ears, 🎶, fo...\n",
       "2     worldforbernie, corrupt, oligarchs, pay, fair,...\n",
       "3     thelibertymove, remember, things, kid, hear, t...\n",
       "4     adelalmalki, tech, news, netflix, shares, plun...\n",
       "5     realalexjones, flashback, irs, insider, expose...\n",
       "6     moveon, day, pa, pays, pattoomey, amp, senateg...\n",
       "7               deadpoolmovie, daddy’s, saving, unicorn\n",
       "8     drjillstein, join, cut, military, budget, amp,...\n",
       "9               deadpoolmovie, daddy’s, saving, unicorn\n",
       "10    gop, day, democrats, eager, hands, americans’,...\n",
       "11    rumsfeldoffice, half, century, filing, correct...\n",
       "12                              natshupe, abolishtheirs\n",
       "13    rogerkver, pay, roads, schools, hospitals, tax...\n",
       "14    drjillstein, best, reign, wasteful, federal, s...\n",
       "15    adelalmalki, tech, news, netflix, shares, plun...\n",
       "16    adelalmalki, tech, news, netflix, shares, plun...\n",
       "17    “government, money, government, finds, money, ...\n",
       "18                       mekhael, mother, officer, time\n",
       "19    berniesanders, youll, returns, year, senator, ...\n",
       "20    berniesanders, youll, returns, year, senator, ...\n",
       "21    lilagracerose, today, reminder, planned, paren...\n",
       "22    hieveryone, ロイターが全世界に報じていた。, japan, pm, sticks...\n",
       "23    baru, keluar, dari, pekerjaan, yang, lama, mau...\n",
       "24                                                     \n",
       "25         deadline, extended, missouri, flood, victims\n",
       "26                 appeal, property, assessment, trulia\n",
       "27    optaxationtheft, taxation, peaceful, solution,...\n",
       "28     video, understanding, alternative, minimum, time\n",
       "29                                      friggin, idiots\n",
       "30    flowermound, lewisville, highlandvillage, cori...\n",
       "31    foxnews, tedcruz, ive, released, years, return...\n",
       "32                                                     \n",
       "33    search, savile, row, amp, rolex, twitter, gues...\n",
       "34    liltunechi, return, start, buying, unnecessary...\n",
       "35    barbitwins, constitutional, demand, abusenokil...\n",
       "36    kylekulinski, bernies, proposed, rates, hypocr...\n",
       "37    markknoller, wh, veto, threat, reduce, funding...\n",
       "38    ruu, amnesty, dinilai, akan, berpengaruh, baik...\n",
       "39    welsh, laborfail, abc, days, year, payer, fund...\n",
       "40        auditthemedia, helped, trend, taxationistheft\n",
       "41              gerfingerpoken, dare, retweet, deadline\n",
       "42                   loan, occupied, house, itr, return\n",
       "43    rationalok, forward, structure, revenue, strea...\n",
       "44    quitmanstephens, april, day, dallas, durandura...\n",
       "45    drjillstein, military, bases, countries, prez,...\n",
       "46    today, day—are, corporations, paying, fair, sh...\n",
       "47                                                     \n",
       "48    ilabreezyi, bathroom, roommate, slipped, remin...\n",
       "49                               tedcruz, abolishtheirs\n",
       "Name: Text_Words, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the cleaned texts look like\n",
    "tweet_df['Text_Words'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "      <th>Text_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>LaTrelleSmart</td>\n",
       "      <td>RT @jackngraham: There are 7 days in a week an...</td>\n",
       "      <td>jackngraham</td>\n",
       "      <td>jackngraham, days, week, someday, day, lord, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal lover, foodie extraordinaire, vintage c...</td>\n",
       "      <td>Calliope116</td>\n",
       "      <td>RT @turbotax: Because the sound of #TaxesDone ...</td>\n",
       "      <td>turbotax</td>\n",
       "      <td>turbotax, sound, taxesdone, music, ears, 🎶, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>mrbacombits</td>\n",
       "      <td>RT @WorldForBernie: Corrupt oligarchs can't ha...</td>\n",
       "      <td>WorldForBernie, BernieSanders, generalelectric</td>\n",
       "      <td>worldforbernie, corrupt, oligarchs, pay, fair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peace, Liberty, Freedom. Politically Uncorrect...</td>\n",
       "      <td>Origanalist</td>\n",
       "      <td>RT @TheLibertyMove: On this #TaxDay let's reme...</td>\n",
       "      <td>TheLibertyMove</td>\n",
       "      <td>thelibertymove, remember, things, kid, hear, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏‏‏‏اللهم إني أعوذ بك من شر ا عملت، ومن شر ما ...</td>\n",
       "      <td>ruthsimpson8641</td>\n",
       "      <td>RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...</td>\n",
       "      <td>Adel__Almalki</td>\n",
       "      <td>adelalmalki, tech, news, netflix, shares, plun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>diazed85</td>\n",
       "      <td>RT @RealAlexJones: FLASHBACK: IRS Insider Expo...</td>\n",
       "      <td>RealAlexJones</td>\n",
       "      <td>realalexjones, flashback, irs, insider, expose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>imzayde</td>\n",
       "      <td>RT @MoveOn: $52,369.35/DAY: Amount PA pays for...</td>\n",
       "      <td>MoveOn, PatToomey, SenateGOP</td>\n",
       "      <td>moveon, day, pa, pays, pattoomey, amp, senateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>princykaundal</td>\n",
       "      <td>RT @deadpoolmovie: Daddy’s still saving up for...</td>\n",
       "      <td>deadpoolmovie</td>\n",
       "      <td>deadpoolmovie, daddy’s, saving, unicorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Being human is being here.</td>\n",
       "      <td>lynn_mistie</td>\n",
       "      <td>RT @DrJillStein: Join my #TaxDay call to cut m...</td>\n",
       "      <td>DrJillStein</td>\n",
       "      <td>drjillstein, join, cut, military, budget, amp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Be a slut do whatever you want</td>\n",
       "      <td>PhilipInTheDark</td>\n",
       "      <td>RT @deadpoolmovie: Daddy’s still saving up for...</td>\n",
       "      <td>deadpoolmovie</td>\n",
       "      <td>deadpoolmovie, daddy’s, saving, unicorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Profile_Description       ScreenName  \\\n",
       "0                                               None    LaTrelleSmart   \n",
       "1  Animal lover, foodie extraordinaire, vintage c...      Calliope116   \n",
       "2                                               None      mrbacombits   \n",
       "3  Peace, Liberty, Freedom. Politically Uncorrect...      Origanalist   \n",
       "4  ‏‏‏‏اللهم إني أعوذ بك من شر ا عملت، ومن شر ما ...  ruthsimpson8641   \n",
       "5                                               None         diazed85   \n",
       "6                                               None          imzayde   \n",
       "7                                               None    princykaundal   \n",
       "8                         Being human is being here.      lynn_mistie   \n",
       "9                     Be a slut do whatever you want  PhilipInTheDark   \n",
       "\n",
       "                                                Text  \\\n",
       "0  RT @jackngraham: There are 7 days in a week an...   \n",
       "1  RT @turbotax: Because the sound of #TaxesDone ...   \n",
       "2  RT @WorldForBernie: Corrupt oligarchs can't ha...   \n",
       "3  RT @TheLibertyMove: On this #TaxDay let's reme...   \n",
       "4  RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...   \n",
       "5  RT @RealAlexJones: FLASHBACK: IRS Insider Expo...   \n",
       "6  RT @MoveOn: $52,369.35/DAY: Amount PA pays for...   \n",
       "7  RT @deadpoolmovie: Daddy’s still saving up for...   \n",
       "8  RT @DrJillStein: Join my #TaxDay call to cut m...   \n",
       "9  RT @deadpoolmovie: Daddy’s still saving up for...   \n",
       "\n",
       "                                    User_Mentions  \\\n",
       "0                                     jackngraham   \n",
       "1                                        turbotax   \n",
       "2  WorldForBernie, BernieSanders, generalelectric   \n",
       "3                                  TheLibertyMove   \n",
       "4                                   Adel__Almalki   \n",
       "5                                   RealAlexJones   \n",
       "6                    MoveOn, PatToomey, SenateGOP   \n",
       "7                                   deadpoolmovie   \n",
       "8                                     DrJillStein   \n",
       "9                                   deadpoolmovie   \n",
       "\n",
       "                                          Text_Words  \n",
       "0  jackngraham, days, week, someday, day, lord, c...  \n",
       "1  turbotax, sound, taxesdone, music, ears, 🎶, fo...  \n",
       "2  worldforbernie, corrupt, oligarchs, pay, fair,...  \n",
       "3  thelibertymove, remember, things, kid, hear, t...  \n",
       "4  adelalmalki, tech, news, netflix, shares, plun...  \n",
       "5  realalexjones, flashback, irs, insider, expose...  \n",
       "6  moveon, day, pa, pays, pattoomey, amp, senateg...  \n",
       "7            deadpoolmovie, daddy’s, saving, unicorn  \n",
       "8  drjillstein, join, cut, military, budget, amp,...  \n",
       "9            deadpoolmovie, daddy’s, saving, unicorn  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first few rows of tweet_df\n",
    "tweet_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Political Affiliation of Twitter Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary library to assign political affiliation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the list of trump followers\n",
    "with open(\"trump2.pickle\", \"rb\") as f:\n",
    "    trump_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of bernie followers\n",
    "bernie_list = []\n",
    "with open(\"bernie.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        bernie_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of hilary followers\n",
    "hilary_list = []\n",
    "with open(\"hilary.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        hilary_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of ted cruz followers\n",
    "cruz_list = []\n",
    "with open(\"cruz.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        cruz_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jkline_TGN', 'PiekarzKinga', 'DCDanielCollazo', 'AlkhaldiFadel', 'jmock89']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the lists loaded correctly\n",
    "len(cruz_list)\n",
    "cruz_list[:5]\n",
    "\n",
    "len(hilary_list)\n",
    "hilary_list[:5]\n",
    "\n",
    "len(trump_list)\n",
    "trump_list[:5]\n",
    "\n",
    "len(bernie_list)\n",
    "bernie_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPoliticalAffiliation(user, profile_desc, user_mentions):\n",
    "    \"\"\"This function returns the label 'dem' or 'rep'\n",
    "    depending on certain criteria.\n",
    "    \"\"\"\n",
    "    # Check to see if the user is a follower of any of the 4 presidential candidates\n",
    "    if user in trump_list:\n",
    "        return \"Rep\"\n",
    "    if user in bernie_list:\n",
    "        return \"Dem\"\n",
    "    if user in hilary_list:\n",
    "        return \"Dem\"\n",
    "    if user in cruz_list:\n",
    "        return \"Rep\"\n",
    "\n",
    "    # Check to see if the user's profile description contain any of the following words\n",
    "    # that are commonly used to describe the two political parties\n",
    "    dem = [\"progressive\", \"democrat\", \"liberal\", \"socialist\", \"egalitarian\", \n",
    "           \"bleeding heart\", \"left-wing\", \"pro-choice\", \"obama\", \"hilary\", \n",
    "           \"clinton\", \"bernie\", \"sanders\"]\n",
    "    gop = [\"conservative\", \"teaparty\", \"tea party\", \"republican\", \"gop\", \n",
    "           \"right-wing\", \"nra\", \"pro-life\", \"trump\", \"cruz\", \"rubio\"]\n",
    "\n",
    "    if profile_desc != None:\n",
    "        profile_list = profile_desc.split()\n",
    "\n",
    "        for word in profile_list:\n",
    "            word = word.lower()\n",
    "            if any(word in profile_list for word in dem):\n",
    "                return \"Dem\"\n",
    "            if any(word in profile_list for word in gop):\n",
    "                return \"Rep\"\n",
    "\n",
    "    # Check if tweet mentioned one of the presidential candidates\n",
    "    mentions_dem_list = [\"WorldForBernie\", \"BernieSanders\", \"HilaryClinton\"]\n",
    "    mentions_rep_list = [\"realDonaldTrump\", \"tedcruz\"]\n",
    "    \n",
    "    if user_mentions != None:\n",
    "        for user in user_mentions:\n",
    "            if any(word in user_mentions for word in mentions_dem_list):\n",
    "                return \"Dem\"\n",
    "            if any(word in user_mentions for word in mentions_rep_list):\n",
    "                return \"Rep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifyPoliticalAffiliation function to tweet_df\n",
    "tweet_df['Political_Affiliation'] = list(map(classifyPoliticalAffiliation, tweet_df[\"ScreenName\"], \n",
    "                                             tweet_df[\"Profile_Description\"], tweet_df[\"User_Mentions\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the Tweets as Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried using the list of positive and negative words as labeled by Finn Årup Nielsen, \n",
    "# but the result was not very good (none of the tweets were labeled as pos or neg) so I had to scrap this idea\n",
    "# Reference: Finn Årup Nielsen, \"A new ANEW: Evaluation of a word list for\n",
    "#            sentiment analysis in microblogs\", http://arxiv.org/abs/1103.2903\n",
    "\n",
    "# afinn_dict = {}\n",
    "\n",
    "# with open(\"AFINN-96.txt\") as f:\n",
    "#     for line in f:\n",
    "#         line_list = line.split('\\t')\n",
    "#         key = line_list[0]\n",
    "#         value = line_list[1]\n",
    "#         afinn_dict[key] = int(value)\n",
    "            \n",
    "# def classifyTaxTweet(word_list):\n",
    "#     \"\"\"Classifies a tweet as 'positive' or 'negative' according to the sum\n",
    "#     of positive and negative words in the tweet.  \n",
    "#     \"\"\"\n",
    "#     score = sum(map(lambda word: afinn_dict.get(word, 0), word_list))\n",
    "#     if score > 0:\n",
    "#         return \"neg\"\n",
    "#     elif score < 0:\n",
    "#         return \"pos\"\n",
    "#     else:\n",
    "#         return \"neutral\"\n",
    "    \n",
    "# # Apply analysis to twitter texts\n",
    "# tweet_df['Text_Class'] = list(map(classifyTaxTweet, tweet_df[\"Text_Words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries for labeling tweets\n",
    "from nltk.corpus import movie_reviews\n",
    "from featx import label_feats_from_corpus, split_label_feats\n",
    "from featx import bag_of_words\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Naive Bayes Classifer on 'Movie Reviews' corpus in NLTK\n",
    "\n",
    "# These codes are taken from the book, Natural language processing with python,\n",
    "# which has been referenced in the bibliography section of my executive summary\n",
    "\n",
    "lfeats = label_feats_from_corpus(movie_reviews)\n",
    "train_feats, test_feats = split_label_feats(lfeats, split=0.75)\n",
    "nb_classifier = NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the bag-of-words approach to analyze the tweets\n",
    "def classifyTaxTweet(word_list):\n",
    "    text = bag_of_words(word_list)\n",
    "    \n",
    "    return nb_classifier.classify(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply analysis to twitter texts\n",
    "tweet_df['Text_Label'] = list(map(classifyTaxTweet, tweet_df[\"Text_Words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "      <th>Text_Words</th>\n",
       "      <th>Political_Affiliation</th>\n",
       "      <th>Text_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text_Label</th>\n",
       "      <th>Political_Affiliation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">neg</th>\n",
       "      <th>Dem</th>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep</th>\n",
       "      <td>163</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pos</th>\n",
       "      <th>Dem</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Profile_Description  ScreenName  Text  \\\n",
       "Text_Label Political_Affiliation                                          \n",
       "neg        Dem                                    133         178   178   \n",
       "           Rep                                    163         211   211   \n",
       "pos        Dem                                     14          14    14   \n",
       "           Rep                                      6           9     9   \n",
       "\n",
       "                                  User_Mentions  Text_Words  \\\n",
       "Text_Label Political_Affiliation                              \n",
       "neg        Dem                              178         178   \n",
       "           Rep                              211         211   \n",
       "pos        Dem                               14          14   \n",
       "           Rep                                9           9   \n",
       "\n",
       "                                  Political_Affiliation  Text_Label  \n",
       "Text_Label Political_Affiliation                                     \n",
       "neg        Dem                                      178         178  \n",
       "           Rep                                      211         211  \n",
       "pos        Dem                                       14          14  \n",
       "           Rep                                        9           9  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at positive & negative tweets by political affiliation\n",
    "tweet_df.groupby([tweet_df['Text_Label'], tweet_df['Political_Affiliation']]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tweet_df to a csv file to import for further analysis in R\n",
    "tweet_df.to_csv('tweet_df.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
