{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Tweet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries/packages\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweeets.json file and parse into a Python dictionary\n",
    "tweet_list = []\n",
    "with open('tax_tweets.json') as f:\n",
    "    for line in f:\n",
    "        tweet_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'contributors': None,\n",
      "  'coordinates': None,\n",
      "  'created_at': 'Tue Apr 19 03:58:52 +0000 2016',\n",
      "  'entities': {'hashtags': [],\n",
      "               'symbols': [],\n",
      "               'urls': [],\n",
      "               'user_mentions': [{'id': 110606529,\n",
      "                                  'id_str': '110606529',\n",
      "                                  'indices': [3, 15],\n",
      "                                  'name': 'Jack Graham',\n",
      "                                  'screen_name': 'jackngraham'}]},\n",
      "  'favorite_count': 0,\n",
      "  'favorited': False,\n",
      "  'filter_level': 'low',\n",
      "  'geo': None,\n",
      "  'id': 722273234150789120,\n",
      "  'id_str': '722273234150789120',\n",
      "  'in_reply_to_screen_name': None,\n",
      "  'in_reply_to_status_id': None,\n",
      "  'in_reply_to_status_id_str': None,\n",
      "  'in_reply_to_user_id': None,\n",
      "  'in_reply_to_user_id_str': None,\n",
      "  'is_quote_status': False,\n",
      "  'lang': 'en',\n",
      "  'place': None,\n",
      "  'retweet_count': 0,\n",
      "  'retweeted': False,\n",
      "  'retweeted_status': {'contributors': None,\n",
      "                       'coordinates': None,\n",
      "                       'created_at': 'Mon Apr 18 12:24:01 +0000 2016',\n",
      "                       'entities': {'hashtags': [],\n",
      "                                    'symbols': [],\n",
      "                                    'urls': [],\n",
      "                                    'user_mentions': []},\n",
      "                       'favorite_count': 49,\n",
      "                       'favorited': False,\n",
      "                       'filter_level': 'low',\n",
      "                       'geo': None,\n",
      "                       'id': 722037969431830529,\n",
      "                       'id_str': '722037969431830529',\n",
      "                       'in_reply_to_screen_name': None,\n",
      "                       'in_reply_to_status_id': None,\n",
      "                       'in_reply_to_status_id_str': None,\n",
      "                       'in_reply_to_user_id': None,\n",
      "                       'in_reply_to_user_id_str': None,\n",
      "                       'is_quote_status': False,\n",
      "                       'lang': 'en',\n",
      "                       'place': None,\n",
      "                       'retweet_count': 18,\n",
      "                       'retweeted': False,\n",
      "                       'source': '<a href=\"http://www.echofon.com/\" '\n",
      "                                 'rel=\"nofollow\">Echofon</a>',\n",
      "                       'text': 'There are 7 days in a week and Someday is not '\n",
      "                               'one of them. This is the day the Lord has '\n",
      "                               'made. Celebrate it even tho it is Taxday!!!',\n",
      "                       'truncated': False,\n",
      "                       'user': {'contributors_enabled': False,\n",
      "                                'created_at': 'Tue Feb 02 04:04:41 +0000 2010',\n",
      "                                'default_profile': True,\n",
      "                                'default_profile_image': False,\n",
      "                                'description': 'Pastor Prestonwood. Speaker '\n",
      "                                               'PowerPoint. Following Jesus. '\n",
      "                                               'Loving my family',\n",
      "                                'favourites_count': 0,\n",
      "                                'follow_request_sent': None,\n",
      "                                'followers_count': 33653,\n",
      "                                'following': None,\n",
      "                                'friends_count': 316,\n",
      "                                'geo_enabled': True,\n",
      "                                'id': 110606529,\n",
      "                                'id_str': '110606529',\n",
      "                                'is_translator': False,\n",
      "                                'lang': 'en',\n",
      "                                'listed_count': 434,\n",
      "                                'location': None,\n",
      "                                'name': 'Jack Graham',\n",
      "                                'notifications': None,\n",
      "                                'profile_background_color': 'C0DEED',\n",
      "                                'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "                                'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "                                'profile_background_tile': False,\n",
      "                                'profile_image_url': 'http://pbs.twimg.com/profile_images/469526860464783360/1Ip_Z2B-_normal.jpeg',\n",
      "                                'profile_image_url_https': 'https://pbs.twimg.com/profile_images/469526860464783360/1Ip_Z2B-_normal.jpeg',\n",
      "                                'profile_link_color': '0084B4',\n",
      "                                'profile_sidebar_border_color': 'C0DEED',\n",
      "                                'profile_sidebar_fill_color': 'DDEEF6',\n",
      "                                'profile_text_color': '333333',\n",
      "                                'profile_use_background_image': True,\n",
      "                                'protected': False,\n",
      "                                'screen_name': 'jackngraham',\n",
      "                                'statuses_count': 8769,\n",
      "                                'time_zone': None,\n",
      "                                'url': 'http://jackgraham.org',\n",
      "                                'utc_offset': None,\n",
      "                                'verified': False}},\n",
      "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web '\n",
      "            'Client</a>',\n",
      "  'text': 'RT @jackngraham: There are 7 days in a week and Someday is not one '\n",
      "          'of them. This is the day the Lord has made. Celebrate it even tho '\n",
      "          'it is‚Ä¶',\n",
      "  'timestamp_ms': '1461038332866',\n",
      "  'truncated': False,\n",
      "  'user': {'contributors_enabled': False,\n",
      "           'created_at': 'Wed Mar 18 05:34:15 +0000 2009',\n",
      "           'default_profile': False,\n",
      "           'default_profile_image': False,\n",
      "           'description': None,\n",
      "           'favourites_count': 928,\n",
      "           'follow_request_sent': None,\n",
      "           'followers_count': 85,\n",
      "           'following': None,\n",
      "           'friends_count': 210,\n",
      "           'geo_enabled': False,\n",
      "           'id': 25034105,\n",
      "           'id_str': '25034105',\n",
      "           'is_translator': False,\n",
      "           'lang': 'en',\n",
      "           'listed_count': 4,\n",
      "           'location': 'Dallas, Texas',\n",
      "           'name': 'LaTrelle Smart',\n",
      "           'notifications': None,\n",
      "           'profile_background_color': '0099B9',\n",
      "           'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme4/bg.gif',\n",
      "           'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme4/bg.gif',\n",
      "           'profile_background_tile': False,\n",
      "           'profile_image_url': 'http://pbs.twimg.com/profile_images/1455451250/LaTrelle_2011_normal.jpg',\n",
      "           'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1455451250/LaTrelle_2011_normal.jpg',\n",
      "           'profile_link_color': '0099B9',\n",
      "           'profile_sidebar_border_color': '5ED4DC',\n",
      "           'profile_sidebar_fill_color': '95E8EC',\n",
      "           'profile_text_color': '3C3940',\n",
      "           'profile_use_background_image': True,\n",
      "           'protected': False,\n",
      "           'screen_name': 'LaTrelleSmart',\n",
      "           'statuses_count': 916,\n",
      "           'time_zone': 'Central Time (US & Canada)',\n",
      "           'url': 'http://smartoutsourcesolutions.com',\n",
      "           'utc_offset': -18000,\n",
      "           'verified': False}}]\n"
     ]
    }
   ],
   "source": [
    "# Check structure of Tweet JSON file\n",
    "pprint.pprint(tweet_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tweet class to store attributes for each tweet\n",
    "\n",
    "class TaxTweets(object):\n",
    "    \n",
    "    def __init__(self, screen_name=\"\", profile_description=\"\", \n",
    "                 text=\"\", user_mentions=\"\"):\n",
    "        self.screen_name = screen_name\n",
    "        self.profile_description = profile_description\n",
    "        self.text = text\n",
    "        self.user_mentions = user_mentions\n",
    "        \n",
    "    def get_screen_name(self):\n",
    "        \"\"\"return screen name of twitter user\"\"\"\n",
    "        return self.screen_name\n",
    "    \n",
    "    def get_profile_description(self):\n",
    "        \"\"\"return profile description of user\"\"\"\n",
    "        return self.profile_description\n",
    "    \n",
    "    def get_text(self):\n",
    "        \"\"\"return text of twitter user\"\"\"\n",
    "        return self.text\n",
    "    \n",
    "    def get_user_mentions(self):\n",
    "        \"\"\"return screen names of users mentioned in tweet\"\"\"\n",
    "        return self.user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store each tweet set of attributes\n",
    "tweet_list2 = []\n",
    "\n",
    "# Iterate over each tweet set and get username, text, users mentioned, and \n",
    "# profile description in the tweet\n",
    "for tweet in tweet_list:\n",
    "    \n",
    "    user_mentions_list = [tweet['entities']['user_mentions'][i]['screen_name']\n",
    "                          for i in range(0, len(tweet['entities']['user_mentions']))]\n",
    "        \n",
    "    tweet_list2.append(TaxTweets(tweet['user']['screen_name'], \n",
    "                                 tweet['user']['description'],\n",
    "                                 tweet['text'],\n",
    "                                 user_mentions_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweets DataFrame\n",
    "\n",
    "# Set column names\n",
    "column_names = ('ScreenName', 'Profile_Description', 'Text', 'User_Mentions')\n",
    "# Create an empty dictionary to hold tweet sets\n",
    "dict_list = []\n",
    "\n",
    "# Iterate over each tweet set in list and zip together tweet attributes along\n",
    "# with column name to create dataframe\n",
    "for tweet in tweet_list2:\n",
    "    dict_list.append(dict(zip(column_names,\n",
    "                                  [tweet.get_screen_name(), \n",
    "                                   tweet.get_profile_description(),\n",
    "                                   tweet.get_text(), \n",
    "                                   tweet.get_user_mentions()\n",
    "                                  ]\n",
    "                             )))\n",
    "\n",
    "# Create tweets dataframe\n",
    "tweet_df = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>Award winning Designer/ Architect/ Design Dire...</td>\n",
       "      <td>RKMustafa</td>\n",
       "      <td>Stop Trying To File Your Tax Returns From Coac...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>Jus a Single laid bac kat who likes 2hav a goo...</td>\n",
       "      <td>DurdyGP</td>\n",
       "      <td>RT @CBSLA: Some Coachella goers tried to mail ...</td>\n",
       "      <td>[CBSLA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>we will see</td>\n",
       "      <td>queensusana24</td>\n",
       "      <td>Press TV Interview: G-20 Crackdown on Tax Have...</td>\n",
       "      <td>[1lefthook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>None</td>\n",
       "      <td>chiquisholla</td>\n",
       "      <td>RT @InmigrantNacion: @JimPressOffice\\n#AINF\\n#...</td>\n",
       "      <td>[InmigrantNacion, JimPressOffice, GOP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>@SpaceX once responded to a mission idea I had...</td>\n",
       "      <td>HAL9000and1</td>\n",
       "      <td>Hi, we're NASA and we want tax payers money......</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>North Broward Preparatory School June 26, 1993</td>\n",
       "      <td>tam1i</td>\n",
       "      <td>6 Good Reasons to File a Tax Extension #TaxDea...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>DissidentRight publishes original work through...</td>\n",
       "      <td>adissidentright</td>\n",
       "      <td>I *almost* pity the people who think of indivi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>None</td>\n",
       "      <td>nanner_lp</td>\n",
       "      <td>RT @micnews: This Michigan lawmaker explains w...</td>\n",
       "      <td>[micnews]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>None</td>\n",
       "      <td>Marchant9876</td>\n",
       "      <td>RT @margokingston1: Albo: Leaks show Govt adop...</td>\n",
       "      <td>[margokingston1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>‚ÄèÿµŸêŸÑŸéÿ™ŸèŸé ÿ®ŸÄ ÿ±ÿ®⁄Ø ÿå ŸáŸäŸéŸë ÿ®Ÿàÿßÿ®ÿ™ŸÉ ŸÑŸÑÿ≠ÿßÿ© ÿåÿå\\nŸàŸé ÿπŸÑŸâ...</td>\n",
       "      <td>victoriasuthe17</td>\n",
       "      <td>RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...</td>\n",
       "      <td>[Adel__Almalki]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Profile_Description       ScreenName  \\\n",
       "4970  Award winning Designer/ Architect/ Design Dire...        RKMustafa   \n",
       "4971  Jus a Single laid bac kat who likes 2hav a goo...          DurdyGP   \n",
       "4972                                        we will see    queensusana24   \n",
       "4973                                               None     chiquisholla   \n",
       "4974  @SpaceX once responded to a mission idea I had...      HAL9000and1   \n",
       "4975     North Broward Preparatory School June 26, 1993            tam1i   \n",
       "4976  DissidentRight publishes original work through...  adissidentright   \n",
       "4977                                               None        nanner_lp   \n",
       "4978                                               None     Marchant9876   \n",
       "4979  ‚ÄèÿµŸêŸÑŸéÿ™ŸèŸé ÿ®ŸÄ ÿ±ÿ®⁄Ø ÿå ŸáŸäŸéŸë ÿ®Ÿàÿßÿ®ÿ™ŸÉ ŸÑŸÑÿ≠ÿßÿ© ÿåÿå\\nŸàŸé ÿπŸÑŸâ...  victoriasuthe17   \n",
       "\n",
       "                                                   Text  \\\n",
       "4970  Stop Trying To File Your Tax Returns From Coac...   \n",
       "4971  RT @CBSLA: Some Coachella goers tried to mail ...   \n",
       "4972  Press TV Interview: G-20 Crackdown on Tax Have...   \n",
       "4973  RT @InmigrantNacion: @JimPressOffice\\n#AINF\\n#...   \n",
       "4974  Hi, we're NASA and we want tax payers money......   \n",
       "4975  6 Good Reasons to File a Tax Extension #TaxDea...   \n",
       "4976  I *almost* pity the people who think of indivi...   \n",
       "4977  RT @micnews: This Michigan lawmaker explains w...   \n",
       "4978  RT @margokingston1: Albo: Leaks show Govt adop...   \n",
       "4979  RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...   \n",
       "\n",
       "                               User_Mentions  \n",
       "4970                                      []  \n",
       "4971                                 [CBSLA]  \n",
       "4972                             [1lefthook]  \n",
       "4973  [InmigrantNacion, JimPressOffice, GOP]  \n",
       "4974                                      []  \n",
       "4975                                      []  \n",
       "4976                                      []  \n",
       "4977                               [micnews]  \n",
       "4978                        [margokingston1]  \n",
       "4979                         [Adel__Almalki]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 10 rows of tweets dataframe\n",
    "tweet_df.head(10)\n",
    "tweet_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries to clean up tweets\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stopwords to remove from tweets\n",
    "# List of stopwords taken from http://stackoverflow.com/questions/5511708/adding-words-to-nltk-stoplist\n",
    "stopword_list = []\n",
    "with open('stopwords.txt') as f:\n",
    "\n",
    "    for line in f:\n",
    "        line = line.split('\\n')\n",
    "        stopword_list.append(line[0])\n",
    "        \n",
    "# Add some Twitter specific words to the list\n",
    "stopword_list.append('rt')\n",
    "stopword_list.append('tax')\n",
    "stopword_list.append('taxday')\n",
    "stopword_list.append('taxes')\n",
    "\n",
    "# Create a string of punctuations and numbers to remove from the tweets\n",
    "punct_num = string.punctuation + string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(wordlist):\n",
    "    \"\"\"\n",
    "    Cleans up string by removing urls, numbers, and punctuations.\n",
    "    Strips white space.  \n",
    "    Makes the words lower case and splits up words.\n",
    "    Removes stop words.\n",
    "    \"\"\"\n",
    "    # Remove urls\n",
    "    # Reference: http://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet\n",
    "    wordlist = re.sub(r\"http\\S+\", \"\", wordlist)\n",
    "    \n",
    "    # Remove punctionations and numbers\n",
    "    for aChar in wordlist:\n",
    "        if aChar in punct_num:\n",
    "            wordlist = wordlist.replace(aChar, '')\n",
    "\n",
    "    # Strip white space, make lower case, and split into words\n",
    "    wordlist = wordlist.strip().lower().split()\n",
    "    \n",
    "    # Filter out stop words\n",
    "    wordlist2 = []\n",
    "    for aWord in wordlist:\n",
    "        if aWord not in stopword_list:\n",
    "            wordlist2.append(aWord)\n",
    "            \n",
    "    \n",
    "            \n",
    "    return wordlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the textProcessing function to tweet_df\n",
    "tweet_df['Text_Words'] = tweet_df['Text'].map(lambda x: textProcessing(x)).map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the User_Mentions column from a list to string\n",
    "tweet_df['User_Mentions'] = tweet_df['User_Mentions'].map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     jackngraham, days, week, someday, day, lord, c...\n",
       "1     turbotax, sound, taxesdone, music, ears, üé∂, fo...\n",
       "2     worldforbernie, corrupt, oligarchs, pay, fair,...\n",
       "3     thelibertymove, remember, things, kid, hear, t...\n",
       "4     adelalmalki, tech, news, netflix, shares, plun...\n",
       "5     realalexjones, flashback, irs, insider, expose...\n",
       "6     moveon, day, pa, pays, pattoomey, amp, senateg...\n",
       "7               deadpoolmovie, daddy‚Äôs, saving, unicorn\n",
       "8     drjillstein, join, cut, military, budget, amp,...\n",
       "9               deadpoolmovie, daddy‚Äôs, saving, unicorn\n",
       "10    gop, day, democrats, eager, hands, americans‚Äô,...\n",
       "11    rumsfeldoffice, half, century, filing, correct...\n",
       "12                              natshupe, abolishtheirs\n",
       "13    rogerkver, pay, roads, schools, hospitals, tax...\n",
       "14    drjillstein, best, reign, wasteful, federal, s...\n",
       "15    adelalmalki, tech, news, netflix, shares, plun...\n",
       "16    adelalmalki, tech, news, netflix, shares, plun...\n",
       "17    ‚Äúgovernment, money, government, finds, money, ...\n",
       "18                       mekhael, mother, officer, time\n",
       "19    berniesanders, youll, returns, year, senator, ...\n",
       "20    berniesanders, youll, returns, year, senator, ...\n",
       "21    lilagracerose, today, reminder, planned, paren...\n",
       "22    hieveryone, „É≠„Ç§„Çø„Éº„ÅåÂÖ®‰∏ñÁïå„Å´Â†±„Åò„Å¶„ÅÑ„Åü„ÄÇ, japan, pm, sticks...\n",
       "23    baru, keluar, dari, pekerjaan, yang, lama, mau...\n",
       "24                                                     \n",
       "25         deadline, extended, missouri, flood, victims\n",
       "26                 appeal, property, assessment, trulia\n",
       "27    optaxationtheft, taxation, peaceful, solution,...\n",
       "28     video, understanding, alternative, minimum, time\n",
       "29                                      friggin, idiots\n",
       "30    flowermound, lewisville, highlandvillage, cori...\n",
       "31    foxnews, tedcruz, ive, released, years, return...\n",
       "32                                                     \n",
       "33    search, savile, row, amp, rolex, twitter, gues...\n",
       "34    liltunechi, return, start, buying, unnecessary...\n",
       "35    barbitwins, constitutional, demand, abusenokil...\n",
       "36    kylekulinski, bernies, proposed, rates, hypocr...\n",
       "37    markknoller, wh, veto, threat, reduce, funding...\n",
       "38    ruu, amnesty, dinilai, akan, berpengaruh, baik...\n",
       "39    welsh, laborfail, abc, days, year, payer, fund...\n",
       "40        auditthemedia, helped, trend, taxationistheft\n",
       "41              gerfingerpoken, dare, retweet, deadline\n",
       "42                   loan, occupied, house, itr, return\n",
       "43    rationalok, forward, structure, revenue, strea...\n",
       "44    quitmanstephens, april, day, dallas, durandura...\n",
       "45    drjillstein, military, bases, countries, prez,...\n",
       "46    today, day‚Äîare, corporations, paying, fair, sh...\n",
       "47                                                     \n",
       "48    ilabreezyi, bathroom, roommate, slipped, remin...\n",
       "49                               tedcruz, abolishtheirs\n",
       "Name: Text_Words, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the cleaned texts look like\n",
    "tweet_df['Text_Words'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "      <th>Text_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>LaTrelleSmart</td>\n",
       "      <td>RT @jackngraham: There are 7 days in a week an...</td>\n",
       "      <td>jackngraham</td>\n",
       "      <td>jackngraham, days, week, someday, day, lord, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal lover, foodie extraordinaire, vintage c...</td>\n",
       "      <td>Calliope116</td>\n",
       "      <td>RT @turbotax: Because the sound of #TaxesDone ...</td>\n",
       "      <td>turbotax</td>\n",
       "      <td>turbotax, sound, taxesdone, music, ears, üé∂, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>mrbacombits</td>\n",
       "      <td>RT @WorldForBernie: Corrupt oligarchs can't ha...</td>\n",
       "      <td>WorldForBernie, BernieSanders, generalelectric</td>\n",
       "      <td>worldforbernie, corrupt, oligarchs, pay, fair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peace, Liberty, Freedom. Politically Uncorrect...</td>\n",
       "      <td>Origanalist</td>\n",
       "      <td>RT @TheLibertyMove: On this #TaxDay let's reme...</td>\n",
       "      <td>TheLibertyMove</td>\n",
       "      <td>thelibertymove, remember, things, kid, hear, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚Äè‚Äè‚Äè‚ÄèÿßŸÑŸÑŸáŸÖ ÿ•ŸÜŸä ÿ£ÿπŸàÿ∞ ÿ®ŸÉ ŸÖŸÜ ÿ¥ÿ± ÿß ÿπŸÖŸÑÿ™ÿå ŸàŸÖŸÜ ÿ¥ÿ± ŸÖÿß ...</td>\n",
       "      <td>ruthsimpson8641</td>\n",
       "      <td>RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...</td>\n",
       "      <td>Adel__Almalki</td>\n",
       "      <td>adelalmalki, tech, news, netflix, shares, plun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>diazed85</td>\n",
       "      <td>RT @RealAlexJones: FLASHBACK: IRS Insider Expo...</td>\n",
       "      <td>RealAlexJones</td>\n",
       "      <td>realalexjones, flashback, irs, insider, expose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>imzayde</td>\n",
       "      <td>RT @MoveOn: $52,369.35/DAY: Amount PA pays for...</td>\n",
       "      <td>MoveOn, PatToomey, SenateGOP</td>\n",
       "      <td>moveon, day, pa, pays, pattoomey, amp, senateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>princykaundal</td>\n",
       "      <td>RT @deadpoolmovie: Daddy‚Äôs still saving up for...</td>\n",
       "      <td>deadpoolmovie</td>\n",
       "      <td>deadpoolmovie, daddy‚Äôs, saving, unicorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Being human is being here.</td>\n",
       "      <td>lynn_mistie</td>\n",
       "      <td>RT @DrJillStein: Join my #TaxDay call to cut m...</td>\n",
       "      <td>DrJillStein</td>\n",
       "      <td>drjillstein, join, cut, military, budget, amp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Be a slut do whatever you want</td>\n",
       "      <td>PhilipInTheDark</td>\n",
       "      <td>RT @deadpoolmovie: Daddy‚Äôs still saving up for...</td>\n",
       "      <td>deadpoolmovie</td>\n",
       "      <td>deadpoolmovie, daddy‚Äôs, saving, unicorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Profile_Description       ScreenName  \\\n",
       "0                                               None    LaTrelleSmart   \n",
       "1  Animal lover, foodie extraordinaire, vintage c...      Calliope116   \n",
       "2                                               None      mrbacombits   \n",
       "3  Peace, Liberty, Freedom. Politically Uncorrect...      Origanalist   \n",
       "4  ‚Äè‚Äè‚Äè‚ÄèÿßŸÑŸÑŸáŸÖ ÿ•ŸÜŸä ÿ£ÿπŸàÿ∞ ÿ®ŸÉ ŸÖŸÜ ÿ¥ÿ± ÿß ÿπŸÖŸÑÿ™ÿå ŸàŸÖŸÜ ÿ¥ÿ± ŸÖÿß ...  ruthsimpson8641   \n",
       "5                                               None         diazed85   \n",
       "6                                               None          imzayde   \n",
       "7                                               None    princykaundal   \n",
       "8                         Being human is being here.      lynn_mistie   \n",
       "9                     Be a slut do whatever you want  PhilipInTheDark   \n",
       "\n",
       "                                                Text  \\\n",
       "0  RT @jackngraham: There are 7 days in a week an...   \n",
       "1  RT @turbotax: Because the sound of #TaxesDone ...   \n",
       "2  RT @WorldForBernie: Corrupt oligarchs can't ha...   \n",
       "3  RT @TheLibertyMove: On this #TaxDay let's reme...   \n",
       "4  RT @Adel__Almalki: #tech #news ( #TaxDay )Netf...   \n",
       "5  RT @RealAlexJones: FLASHBACK: IRS Insider Expo...   \n",
       "6  RT @MoveOn: $52,369.35/DAY: Amount PA pays for...   \n",
       "7  RT @deadpoolmovie: Daddy‚Äôs still saving up for...   \n",
       "8  RT @DrJillStein: Join my #TaxDay call to cut m...   \n",
       "9  RT @deadpoolmovie: Daddy‚Äôs still saving up for...   \n",
       "\n",
       "                                    User_Mentions  \\\n",
       "0                                     jackngraham   \n",
       "1                                        turbotax   \n",
       "2  WorldForBernie, BernieSanders, generalelectric   \n",
       "3                                  TheLibertyMove   \n",
       "4                                   Adel__Almalki   \n",
       "5                                   RealAlexJones   \n",
       "6                    MoveOn, PatToomey, SenateGOP   \n",
       "7                                   deadpoolmovie   \n",
       "8                                     DrJillStein   \n",
       "9                                   deadpoolmovie   \n",
       "\n",
       "                                          Text_Words  \n",
       "0  jackngraham, days, week, someday, day, lord, c...  \n",
       "1  turbotax, sound, taxesdone, music, ears, üé∂, fo...  \n",
       "2  worldforbernie, corrupt, oligarchs, pay, fair,...  \n",
       "3  thelibertymove, remember, things, kid, hear, t...  \n",
       "4  adelalmalki, tech, news, netflix, shares, plun...  \n",
       "5  realalexjones, flashback, irs, insider, expose...  \n",
       "6  moveon, day, pa, pays, pattoomey, amp, senateg...  \n",
       "7            deadpoolmovie, daddy‚Äôs, saving, unicorn  \n",
       "8  drjillstein, join, cut, military, budget, amp,...  \n",
       "9            deadpoolmovie, daddy‚Äôs, saving, unicorn  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first few rows of tweet_df\n",
    "tweet_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Political Affiliation of Twitter Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary library to assign political affiliation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the list of trump followers\n",
    "with open(\"trump2.pickle\", \"rb\") as f:\n",
    "    trump_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of bernie followers\n",
    "bernie_list = []\n",
    "with open(\"bernie.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        bernie_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of hilary followers\n",
    "hilary_list = []\n",
    "with open(\"hilary.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        hilary_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the list of ted cruz followers\n",
    "cruz_list = []\n",
    "with open(\"cruz.pickle\", \"rb\") as f:\n",
    "    dump = pickle.load(f)\n",
    "    \n",
    "    # Get screen name of bernie followers\n",
    "    for user in dump:\n",
    "        cruz_list.append(user.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jkline_TGN', 'PiekarzKinga', 'DCDanielCollazo', 'AlkhaldiFadel', 'jmock89']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the lists loaded correctly\n",
    "len(cruz_list)\n",
    "cruz_list[:5]\n",
    "\n",
    "len(hilary_list)\n",
    "hilary_list[:5]\n",
    "\n",
    "len(trump_list)\n",
    "trump_list[:5]\n",
    "\n",
    "len(bernie_list)\n",
    "bernie_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPoliticalAffiliation(user, profile_desc, user_mentions):\n",
    "    \"\"\"This function returns the label 'dem' or 'rep'\n",
    "    depending on certain criteria.\n",
    "    \"\"\"\n",
    "    # Check to see if the user is a follower of any of the 4 presidential candidates\n",
    "    if user in trump_list:\n",
    "        return \"Rep\"\n",
    "    if user in bernie_list:\n",
    "        return \"Dem\"\n",
    "    if user in hilary_list:\n",
    "        return \"Dem\"\n",
    "    if user in cruz_list:\n",
    "        return \"Rep\"\n",
    "\n",
    "    # Check to see if the user's profile description contain any of the following words\n",
    "    # that are commonly used to describe the two political parties\n",
    "    dem = [\"progressive\", \"democrat\", \"liberal\", \"socialist\", \"egalitarian\", \n",
    "           \"bleeding heart\", \"left-wing\", \"pro-choice\", \"obama\", \"hilary\", \n",
    "           \"clinton\", \"bernie\", \"sanders\"]\n",
    "    gop = [\"conservative\", \"teaparty\", \"tea party\", \"republican\", \"gop\", \n",
    "           \"right-wing\", \"nra\", \"pro-life\", \"trump\", \"cruz\", \"rubio\"]\n",
    "\n",
    "    if profile_desc != None:\n",
    "        profile_list = profile_desc.split()\n",
    "\n",
    "        for word in profile_list:\n",
    "            word = word.lower()\n",
    "            if any(word in profile_list for word in dem):\n",
    "                return \"Dem\"\n",
    "            if any(word in profile_list for word in gop):\n",
    "                return \"Rep\"\n",
    "\n",
    "    # Check if tweet mentioned one of the presidential candidates\n",
    "    mentions_dem_list = [\"WorldForBernie\", \"BernieSanders\", \"HilaryClinton\"]\n",
    "    mentions_rep_list = [\"realDonaldTrump\", \"tedcruz\"]\n",
    "    \n",
    "    if user_mentions != None:\n",
    "        for user in user_mentions:\n",
    "            if any(word in user_mentions for word in mentions_dem_list):\n",
    "                return \"Dem\"\n",
    "            if any(word in user_mentions for word in mentions_rep_list):\n",
    "                return \"Rep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifyPoliticalAffiliation function to tweet_df\n",
    "tweet_df['Political_Affiliation'] = list(map(classifyPoliticalAffiliation, tweet_df[\"ScreenName\"], \n",
    "                                             tweet_df[\"Profile_Description\"], tweet_df[\"User_Mentions\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the Tweets as Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried using the list of positive and negative words as labeled by Finn √Örup Nielsen, \n",
    "# but the result was not very good (none of the tweets were labeled as pos or neg) so I had to scrap this idea\n",
    "# Reference: Finn √Örup Nielsen, \"A new ANEW: Evaluation of a word list for\n",
    "#            sentiment analysis in microblogs\", http://arxiv.org/abs/1103.2903\n",
    "\n",
    "# afinn_dict = {}\n",
    "\n",
    "# with open(\"AFINN-96.txt\") as f:\n",
    "#     for line in f:\n",
    "#         line_list = line.split('\\t')\n",
    "#         key = line_list[0]\n",
    "#         value = line_list[1]\n",
    "#         afinn_dict[key] = int(value)\n",
    "            \n",
    "# def classifyTaxTweet(word_list):\n",
    "#     \"\"\"Classifies a tweet as 'positive' or 'negative' according to the sum\n",
    "#     of positive and negative words in the tweet.  \n",
    "#     \"\"\"\n",
    "#     score = sum(map(lambda word: afinn_dict.get(word, 0), word_list))\n",
    "#     if score > 0:\n",
    "#         return \"neg\"\n",
    "#     elif score < 0:\n",
    "#         return \"pos\"\n",
    "#     else:\n",
    "#         return \"neutral\"\n",
    "    \n",
    "# # Apply analysis to twitter texts\n",
    "# tweet_df['Text_Class'] = list(map(classifyTaxTweet, tweet_df[\"Text_Words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries for labeling tweets\n",
    "from nltk.corpus import movie_reviews\n",
    "from featx import label_feats_from_corpus, split_label_feats\n",
    "from featx import bag_of_words\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Naive Bayes Classifer on 'Movie Reviews' corpus in NLTK\n",
    "\n",
    "# These codes are taken from the book, Natural language processing with python,\n",
    "# which has been referenced in the bibliography section of my executive summary\n",
    "\n",
    "lfeats = label_feats_from_corpus(movie_reviews)\n",
    "train_feats, test_feats = split_label_feats(lfeats, split=0.75)\n",
    "nb_classifier = NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the bag-of-words approach to analyze the tweets\n",
    "def classifyTaxTweet(word_list):\n",
    "    text = bag_of_words(word_list)\n",
    "    \n",
    "    return nb_classifier.classify(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply analysis to twitter texts\n",
    "tweet_df['Text_Label'] = list(map(classifyTaxTweet, tweet_df[\"Text_Words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Profile_Description</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Mentions</th>\n",
       "      <th>Text_Words</th>\n",
       "      <th>Political_Affiliation</th>\n",
       "      <th>Text_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text_Label</th>\n",
       "      <th>Political_Affiliation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">neg</th>\n",
       "      <th>Dem</th>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep</th>\n",
       "      <td>163</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pos</th>\n",
       "      <th>Dem</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Profile_Description  ScreenName  Text  \\\n",
       "Text_Label Political_Affiliation                                          \n",
       "neg        Dem                                    133         178   178   \n",
       "           Rep                                    163         211   211   \n",
       "pos        Dem                                     14          14    14   \n",
       "           Rep                                      6           9     9   \n",
       "\n",
       "                                  User_Mentions  Text_Words  \\\n",
       "Text_Label Political_Affiliation                              \n",
       "neg        Dem                              178         178   \n",
       "           Rep                              211         211   \n",
       "pos        Dem                               14          14   \n",
       "           Rep                                9           9   \n",
       "\n",
       "                                  Political_Affiliation  Text_Label  \n",
       "Text_Label Political_Affiliation                                     \n",
       "neg        Dem                                      178         178  \n",
       "           Rep                                      211         211  \n",
       "pos        Dem                                       14          14  \n",
       "           Rep                                        9           9  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at positive & negative tweets by political affiliation\n",
    "tweet_df.groupby([tweet_df['Text_Label'], tweet_df['Political_Affiliation']]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tweet_df to a csv file to import for further analysis in R\n",
    "tweet_df.to_csv('tweet_df.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
